{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from scipy import ndimage\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real(ish) World Example\n",
    "#### Creating a active transit priority index for Oakland\n",
    "\n",
    "Please borrow and improve on the code! <br>\n",
    "It is set up to run with minimal input from the user. <br>\n",
    "It uses census shapefiles, crash data from TIMS, and census demographic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Set Geography for Analysis\n",
    "\n",
    "Start by selecting the spatial information for the Census block group. <br>\n",
    "Start by Downloading Geography <br>\n",
    "Files are from Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_places = gpd.read_file(\"Spatial Files/tl_2019_06_place.shp\")\n",
    "block_gr = gpd.read_file(\"Spatial Files/tl_2019_06_bg.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by selecting Oakland from places file using name\n",
    "place = census_places[census_places['NAME'] == 'Oakland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use overlay function to select only for Census Block groups inside of Oakland\n",
    "bl_gr = gpd.overlay(place, block_gr, how = \"intersection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoID_2 represents the block group code\n",
    "bl_gr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple copy of the bl_stock that retains id and geography\n",
    "bl_simp = bl_gr[['GEOID_2','geometry']].reset_index()\n",
    "place_simp = place[['NAME','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what we have\n",
    "bl_simp.plot(figsize = (5, 5), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.5).set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the ugly hanging Tract that is entirely in the bay.\n",
    "# I identified it by fiding the tract with the most water in it\n",
    "bl_simp = bl_simp[bl_simp['GEOID_2'] != '060019900000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_simp.plot(figsize = (5, 5), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.5).set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Attach Geospatial Data - Ped and Bike Crashes\n",
    "This part of the code loads and cleans crash data from TIMS. <br>\n",
    "The crashes are for 5 years of data for Oakland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_cr = gpd.read_file(\"Spatial Files/oakland_ped_collisions.shp\")\n",
    "bike_cr = gpd.read_file(\"Spatial Files/oakland_bike_collisions.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller simpler dataframe\n",
    "# Saving Case_ID, Crash Severity, and geometry\n",
    "# Crash severity is in the column labelled \"COLLISIO_1\n",
    "\n",
    "ped_cr_sh = ped_cr[['CASE_ID','COLLISIO_1','geometry']]\n",
    "ped_cr_sh = ped_cr_sh.rename(columns={\"CASE_ID\": \"ped_ID\", \"COLLISIO_1\": \"ped_sev\"})\n",
    "ped_cr_sh['count_ped'] = 1\n",
    "bike_cr_sh = bike_cr[['CASE_ID','COLLISIO_1','geometry']]\n",
    "bike_cr_sh = bike_cr_sh.rename(columns={\"CASE_ID\": \"bike_ID\", \"COLLISIO_1\": \"bike_sev\"})\n",
    "bike_cr_sh['count_bike'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject census block group data into the same projection\n",
    "\n",
    "bl_simp = bl_simp.to_crs(ped_cr_sh.crs)\n",
    "place_simp = place_simp.to_crs(ped_cr_sh.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove crashes that are outside of Oakland borders\n",
    "\n",
    "ped_cr_sh = gpd.sjoin(ped_cr_sh, place_simp, how = 'inner').drop(columns = ['NAME','index_right'])\n",
    "bike_cr_sh = gpd.sjoin(bike_cr_sh, place_simp, how = 'inner').drop(columns = ['NAME','index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot what we have\n",
    "\n",
    "ax = bl_simp.plot(figsize = (10, 10), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.5)\n",
    "ax = ped_cr_sh.plot(ax =ax, color = 'Blue', alpha = 0.5) # alpha allows you to make layers transparent\n",
    "bike_cr_sh.plot(ax =ax, color = 'Purple', alpha = 0.5).set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modifying Spatial Data\n",
    "#### ACTION STEP - 1\n",
    "#### 2.1 Determine Distance Consideration\n",
    "How close should a crash be to a block group to be considered an impact on residents?<br/>\n",
    "We can use buffering to change the area under consideration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the CRS to determine the projection being used and the scale for measurements.\n",
    "# We are using us-ft.\n",
    "\n",
    "ped_cr.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACTION STEP IS HERE\n",
    "How close to a block group should be a crash be for us to consider it\n",
    "an impact on them? <br>\n",
    "You decide? (Remember we are measuring in feet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_buffer = 5280/4 # Quarter mile\n",
    "bike_buffer = (5280) # Mile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform point geometry into polygons\n",
    "# Geometry become \"impact area\" of a crash\n",
    "ped_cr_sh['geometry'] = ped_cr_sh['geometry'].buffer(ped_buffer)\n",
    "bike_cr_sh['geometry'] = bike_cr_sh['geometry'].buffer(bike_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what we created\n",
    "# Circles show the \"influence\" areas for crashes\n",
    "# Alpha - use for creating transparency\n",
    "\n",
    "ax = bl_simp.plot(figsize = (10, 10), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.1)\n",
    "ax = bike_cr_sh.plot(ax =ax, facecolor = \"none\", edgecolor = \"Purple\", alpha = 0.1)\n",
    "ped_cr_sh.plot(ax =ax, facecolor = \"none\", edgecolor = \"Blue\", alpha = 0.1).set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTION STEP - 2\n",
    "#### 2.2 Weight crashes by severity\n",
    "We are now going to create a metric based on the severity of the crashes. <br>\n",
    "How should we compare more or less severe crashes. Not all crashes are equal <br>\n",
    "but how should we compare them to create a composite score?\n",
    "\n",
    "There are four types of severities in the dataset (note Property Damage Only crashes are not included)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What severity should be given to each crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You decide... the default gives fatal and severe crashes twice as much weight.\n",
    "\n",
    "fatal = 5\n",
    "severe = 5\n",
    "visible = 1\n",
    "comp_pain = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can ignore this part of the code if you would like...\n",
    "It is creating the weighted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code adds a severity weight column\n",
    "\n",
    "ped_cr_sh['p_sev_wt'] = 1\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 1] = fatal\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 2] = severe\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 3] = visible\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 4] = comp_pain\n",
    "\n",
    "bike_cr_sh['b_sev_wt'] = 1\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 1] = fatal\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 2] = severe\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 3] = visible\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 4] = comp_pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join crashes to block groups. Sjoin will create a location record for each overlap of a crash buffer and the block group\n",
    "\n",
    "bl_ped = gpd.sjoin(bl_simp, ped_cr_sh, how = 'left').drop(columns = ['index_right'])\n",
    "bl_bike = gpd.sjoin(bl_simp, bike_cr_sh, how = 'left').drop(columns = ['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes the data into tables organized by block group.\n",
    "\n",
    "bl_sum_ped = bl_ped.groupby(['GEOID_2'])['count_ped','p_sev_wt'].sum().reset_index()\n",
    "bl_sum_bike = bl_bike.groupby(['GEOID_2'])['count_bike','b_sev_wt'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins the data into a single table.\n",
    "\n",
    "bl_analysis = bl_sum_ped.merge(bl_sum_bike, on = 'GEOID_2')\n",
    "bl_analysis = bl_simp.merge(bl_analysis, on = 'GEOID_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fun with Maps!!!\n",
    "Python maps are not a pretty as what you can make in other programs...\n",
    "BUT you can make a lot of maps really quickly. The code below creates <br>\n",
    "a map based on the information in each column in the list.\n",
    "Feel free to speal the code to generate your own maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a usefule bit of code for clipping your spatial files by a box around your data\n",
    "# The script creates a box around the data you want to display\n",
    "# Then you can use the polygon to \"clip\" down features you want to include in your map.\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "bbox = bl_analysis.total_bounds\n",
    "\n",
    "p1 = Point(bbox[0], bbox[3])\n",
    "p2 = Point(bbox[2], bbox[3])\n",
    "p3 = Point(bbox[2], bbox[1])\n",
    "p4 = Point(bbox[0], bbox[1])\n",
    "\n",
    "np1 = (p1.coords.xy[0][0], p1.coords.xy[1][0])\n",
    "np2 = (p2.coords.xy[0][0], p2.coords.xy[1][0])\n",
    "np3 = (p3.coords.xy[0][0], p3.coords.xy[1][0])\n",
    "np4 = (p4.coords.xy[0][0], p4.coords.xy[1][0])\n",
    "\n",
    "bb_polygon = Polygon([np1, np2, np3, np4])\n",
    "cut_shape = gpd.GeoDataFrame(gpd.GeoSeries(bb_polygon), columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added geographic characteristics\n",
    "# These are so I can make an ok -> good looking visualization\n",
    "# Make sure to set layer to same projections otherwise the clip doesn't work\n",
    "\n",
    "# Places\n",
    "census_places = census_places.to_crs(bl_analysis.crs) # Census Bureau\n",
    "# Major roads from Census\n",
    "roads = gpd.read_file(\"Spatial Files/tl_2019_06_prisecroads.shp\") # Census Bureau\n",
    "roads = roads.to_crs(bl_analysis.crs)\n",
    "# Parks from Oakland Opend Data Portal\n",
    "parks = gpd.read_file('Spatial Files/geo_export_2c4cc7cb-4b1e-4799-91d1-693aa89a9e80.shp') # City of Oakland\n",
    "parks = parks.to_crs(bl_analysis.crs)\n",
    "# Water\n",
    "water = gpd.read_file('Spatial Files/water.shp') # MTC ABAG\n",
    "water = water.to_crs(bl_analysis.crs)\n",
    "water2 = gpd.read_file('Spatial Files/WaterMerged.shp') # MTC ABAG\n",
    "water2 = water2.to_crs(bl_analysis.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip using the overlay command from geopandas\n",
    "\n",
    "census_p = gpd.overlay(census_places, cut_shape, how = 'intersection')\n",
    "roads['geometry'] = roads['geometry'].buffer(60)\n",
    "roads = gpd.overlay(roads, cut_shape, how = 'intersection')\n",
    "water = gpd.overlay(water, cut_shape,how = 'intersection')\n",
    "water2 = gpd.overlay(water2, cut_shape, how = 'intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in ['count_ped', 'p_sev_wt','count_bike','p_sev_wt']:\n",
    "    ax = census_p.plot(figsize = (15, 15), color = 'whitesmoke', edgecolor = \"grey\", linewidth = 0.5)\n",
    "    ax = bl_analysis.plot(ax =ax, scheme = \"quantiles\", k = 6, column = x, cmap = \"BuPu\",edgecolor = \"lightgrey\", linewidth = 0.5, legend = True)\n",
    "    ax = parks.plot(ax = ax, color = 'lightgreen')\n",
    "    ax = roads.plot(ax = ax, color = 'white')\n",
    "    ax = census_p.plot(ax =ax, color = 'None', edgecolor = \"grey\", linewidth = 0.5)\n",
    "    ax = water.plot(ax = ax, color = 'lightblue')\n",
    "    ax = water2.plot(ax = ax, color = 'lightblue')\n",
    "    leg = ax.get_legend()\n",
    "    leg.set_bbox_to_anchor((0., 0., 0.2, 0.2))\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(x, fontsize=15, loc = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Managing Data\n",
    "#### 4.1 Normalizing the data\n",
    "For our purposes we will want to normalize the variables summarizing the crash data. <br>\n",
    "This will allow us to more easily factor the results into a composite index in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scores normalized as percent of highest value\n",
    "bl_analysis['c_ped_perc'] = bl_analysis['count_ped']/bl_analysis['count_ped'].max()\n",
    "bl_analysis['sev_ped_perc'] = bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max()\n",
    "bl_analysis['c_bike_perc'] = bl_analysis['count_bike']/bl_analysis['count_bike'].max()\n",
    "bl_analysis['sev_bike_perc'] = bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Add Census Information\n",
    "This step brings in census data that we've downloaded from social explorer and done some minor <br>\n",
    "cleaning. It includes a set of variables described in a table we've hopefully provided to you for <br>\n",
    "the lab (fingers crossed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.read_csv(\"data/alamedacounty_mostly_computed_indices.csv\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the table to our work from above based on the block group\n",
    "We've also included some work to drop columns that are not necessary to keep things more clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['join_id'] = bl_analysis['GEOID_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['join_id'] = indices['Geo_GEOID'].str[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis = bl_analysis.merge(indices, on = 'join_id').drop(columns = ['join_id', 'Geo_FIPS', 'Geo_GEOID', 'Geo_NAME', 'Geo_QName',\n",
    "       'Geo_STUSAB', 'Geo_SUMLEV', 'Geo_GEOCOMP', 'Geo_FILEID', 'Geo_LOGRECNO',\n",
    "       'Geo_US', 'Geo_REGION', 'Geo_DIVISION', 'Geo_STATECE', 'Geo_STATE',\n",
    "       'Geo_COUNTY', 'Geo_COUSUB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's look at what we have!\n",
    "We are going to use that same mapping code from before to see what the variables look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in ['avg.hh.size', 'coc.population', 'total.population',\n",
    "       'elderly.population', 'households', 'limited.english.households',\n",
    "       'poverty.population', 'pop.poverty.determined', 'single.parent.fam',\n",
    "       'families', 'youth.population', 'occupied.housing.units',\n",
    "       'zero.vehicle.hh', 'coc.population.pct', 'elderly.population.pct',\n",
    "       'limited.english.households.pct', 'poverty.population.pct',\n",
    "       'single.parent.fam.pct', 'youth.population.pct', 'zero.vehicle.hh.pct',\n",
    "       'coc.pop.norm', 'elderly.pop.norm', 'limited.english.households.norm',\n",
    "       'poverty.population.norm', 'single.parent.fam.norm',\n",
    "       'youth.population.norm', 'zero.vehicle.hh.norm']:\n",
    "    ax = census_p.plot(figsize = (15, 15), color = 'whitesmoke', edgecolor = \"grey\", linewidth = 0.5)\n",
    "    ax = bl_analysis.plot(ax =ax, scheme = \"quantiles\", k = 6, column = x, cmap = \"BuPu\",edgecolor = \"lightgrey\", linewidth = 0.5, legend = True)\n",
    "    ax = parks.plot(ax = ax, color = 'lightgreen')\n",
    "    ax = roads.plot(ax = ax, color = 'white')\n",
    "    ax = census_p.plot(ax =ax, color = 'None', edgecolor = \"grey\", linewidth = 0.5)\n",
    "    ax = water.plot(ax = ax, color = 'lightblue')\n",
    "    ax = water2.plot(ax = ax, color = 'lightblue')\n",
    "    leg = ax.get_legend()\n",
    "    leg.set_bbox_to_anchor((0., 0., 0.2, 0.2))\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(x, fontsize=15, loc = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Create an Index\n",
    "#### ACTION STEP - 3\n",
    "#### Where should we prioritize active transportation investments?\n",
    "We have all the data. But now the hard questions... <br>\n",
    "What factors should we consider to prioritize resources. <br>\n",
    "We included three starter indecise: (1) Crash Only, (2) Census Factors Only, (3) Simple All Factors.\n",
    "They are not that good. Make us something better... whatever that means. <br>\n",
    "Go down to indecis 4 and 5 to start making your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index1'] = \\\n",
    "        bl_analysis['c_ped_perc'] * 1 + \\\n",
    "        bl_analysis['sev_ped_perc'] * 1 + \\\n",
    "        bl_analysis['c_bike_perc'] * 1 + \\\n",
    "        bl_analysis['sev_bike_perc'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index2'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1 + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index3'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1  + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1  + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 4 + \\\n",
    "        bl_analysis['count_ped']/bl_analysis['count_ped'].max() * 2 + \\\n",
    "        bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max() * 2 + \\\n",
    "        bl_analysis['count_bike']/bl_analysis['count_bike'].max() * 2 + \\\n",
    "        bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max() * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The easiest way to make your index is to change the weighting factor already in the code\n",
    "0 is the same as deleting the factor\n",
    "And... Keep creating if we have actually left enough time for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index4'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 5 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 2  + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 0 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 5 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 0 + \\\n",
    "        bl_analysis['youth.population.pct'] * 8 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 8 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 10  + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 0 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 0 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 0 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 0 + \\\n",
    "        bl_analysis['youth.population.norm'] * 0 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 0 + \\\n",
    "        bl_analysis['count_ped']/bl_analysis['count_ped'].max() * 0 + \\\n",
    "        bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max() * 10 + \\\n",
    "        bl_analysis['count_bike']/bl_analysis['count_bike'].max() * 0 + \\\n",
    "        bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max() * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index5'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1  + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1  + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 4 + \\\n",
    "        bl_analysis['count_ped']/bl_analysis['count_ped'].max() * 2 + \\\n",
    "        bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max() * 2 + \\\n",
    "        bl_analysis['count_bike']/bl_analysis['count_bike'].max() * 2 + \\\n",
    "        bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max() * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in ['index1','index2','index3','index4','index5']:\n",
    "    ax = census_p.plot(figsize = (15, 15), color = 'whitesmoke', edgecolor = \"grey\", linewidth = 0.5)\n",
    "    ax = bl_analysis.plot(ax =ax, scheme = \"quantiles\", k = 6, column = x, cmap = \"pink_r\",edgecolor = \"lightgrey\", linewidth = 0.5, legend = True)\n",
    "    ax = parks.plot(ax = ax, color = 'lightgreen')\n",
    "    ax = roads.plot(ax = ax, color = 'white')\n",
    "    ax = census_p.plot(ax =ax, color = 'None', edgecolor = \"grey\", linewidth = 0.5)\n",
    "    ax = water.plot(ax = ax, color = 'lightblue')\n",
    "    ax = water2.plot(ax = ax, color = 'lightblue')\n",
    "    leg = ax.get_legend()\n",
    "    leg.set_bbox_to_anchor((0., 0., 0.2, 0.2))\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(x, fontsize=15, loc = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Action Item\n",
    "#### Pick your preferred index and send it to us.\n",
    "At the end we will put them on the board. <br>\n",
    "For simplicity just copy the image and email it to us.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
